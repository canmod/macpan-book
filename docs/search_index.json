[["index.html", "Using McMasterPandemic 1 Fast and Flexible Modelling with McMasterPandemic 1.1 History and Motivation 1.2 Installation 1.3 Dependencies 1.4 Generalized Model at a Glance 1.5 Vision and Direction", " Using McMasterPandemic Steve Walker 2023-01-30 1 Fast and Flexible Modelling with McMasterPandemic McMasterPandemic is a modelling tool that was rapidly developed to provide timely insights into the Covid-19 Pandemic in Canada. We are currently refactoring this tool so that it is faster and more general. This guide describes how to use this refactored version of McMasterPandemic. 1.1 History and Motivation 1.1.1 COVID-19 Forecasts McMasterPandemic has been used to do interesting things like predict the third wave of the COVID-19 pandemic in Ontario Canada when case numbers were going down. 1.1.2 Calibration to data McMasterPandemic has not just been an epidemic simulation tool, but can also be used to formally calibrate to data. The following animation provides an illustrative example. observed case reports – dots simulated case reports – line transmission rate optimized using maximum likelihood negative binomial error model 1.1.3 Speed As the COVID-19 pandemic progressed, the following scenario became more common. Public health modeller has to make weekly forecasts Model fitting/calibration takes two days Only three days to explore scenarios write the report No time to refine the model or messaging So we refactored the McMasterPandemic engine using the TMB C++ framework, which resulted in the following unsolicited feedback from a senior research scientist at the Public Health Agency of Canada. “It is insanely fast and definitely saves me hours everyday and allows me to explore more scenarios. I can do many more things I couldn’t do before due to computational limitations.” 1.1.4 Model Extensibility Another common scenario also arose throughout the COVID-19 pandemic progressed. New variant emerges, as immunity from vaccination wanes Public health modeller has to create new model structure Requires a few weeks of software development Public health situation changes over this time Model is less relevant when complete In response to this we built an interface allowing users to create their own compartmental model structure. sir = (flexmodel( params = c(beta = 0.1, gamma = 0.01, N = 100), state = c(S = 99, I = 1, R = 0), start_date = &quot;2020-03-11&quot;, end_date = &quot;2020-12-01&quot; ) %&gt;% add_rate(&quot;S&quot;, &quot;I&quot;, ~ (I) * (beta) * (1/N)) %&gt;% add_rate(&quot;I&quot;, &quot;R&quot;, ~ (gamma)) ) This library of models is a quick-start guide with the following examples: SIR, SI, SEIR, two-strain SIR, Erlang SEIR, SIRV, variolation SIR, SEIRD, BC’s model of the Omicron COVID variant, and Classic McMasterPandemic. 1.2 Installation This generalized McMasterPandemic framework is still in an experimental phase. Therefore you will need to install the tmb-condense code branch that contains the experimental implementation directly from github. A convenient way to do this is to use the remotes package as follows. remotes::install_github(&quot;mac-theobio/McMasterPandemic@tmb-condense&quot;) 1.3 Dependencies ## Warning in checkMatrixPackageVersion(): Package version inconsistency detected. ## TMB was built with Matrix version 1.5.3 ## Current Matrix version is 1.5.1 ## Please re-install &#39;TMB&#39; from source using install.packages(&#39;TMB&#39;, type = &#39;source&#39;) or ask CRAN for a binary version of &#39;TMB&#39; matching CRAN&#39;s &#39;Matrix&#39; package This guide makes use of the following session. sessionInfo() ## R version 4.2.2 (2022-10-31) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Big Sur ... 10.16 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats4 stats graphics grDevices utils datasets methods ## [8] base ## ## other attached packages: ## [1] tmbstan_1.0.4 rstan_2.21.8 StanHeaders_2.21.0-7 ## [4] bbmle_1.0.25 visNetwork_2.1.2 lubridate_1.9.1 ## [7] tidyr_1.3.0 McMasterPandemic_0.2.0.0 dplyr_1.1.0 ## [10] RcppEigen_0.3.3.9.3 TMB_1.9.2 ggplot2_3.4.0 ## ## loaded via a namespace (and not attached): ## [1] sass_0.4.5 jsonlite_1.8.4 splines_4.2.2 ## [4] foreach_1.5.2 bslib_0.4.2 RcppParallel_5.1.6 ## [7] brio_1.1.3 highr_0.10 yaml_2.3.7 ## [10] numDeriv_2016.8-1.1 diagram_1.6.5 pillar_1.8.1 ## [13] lattice_0.20-45 glue_1.6.2 digest_0.6.31 ## [16] colorspace_2.1-0 htmltools_0.5.4 Matrix_1.5-1 ## [19] pkgconfig_2.0.3 bookdown_0.32 purrr_1.0.1 ## [22] mvtnorm_1.1-3 scales_1.2.1 processx_3.8.0 ## [25] tzdb_0.3.0 timechange_0.2.0 tibble_3.1.8 ## [28] generics_0.1.3 ellipsis_0.3.2 cachem_1.0.6 ## [31] withr_2.5.0 cli_3.6.0 magrittr_2.0.3 ## [34] crayon_1.5.2 evaluate_0.20 ps_1.7.2 ## [37] fansi_1.0.4 MASS_7.3-58.1 forcats_1.0.0 ## [40] pkgbuild_1.4.0 loo_2.5.1 prettyunits_1.1.1 ## [43] tools_4.2.2 hms_1.1.2 matrixStats_0.63.0 ## [46] lifecycle_1.0.3 stringr_1.5.0 munsell_0.5.0 ## [49] callr_3.7.3 compiler_4.2.2 jquerylib_0.1.4 ## [52] rlang_1.0.6 grid_4.2.2 iterators_1.0.14 ## [55] rstudioapi_0.14 htmlwidgets_1.6.1 rmarkdown_2.20 ## [58] testthat_3.1.6 gtable_0.3.1 codetools_0.2-18 ## [61] inline_0.3.19 R6_2.5.1 gridExtra_2.3 ## [64] zoo_1.8-11 knitr_1.42 bdsmatrix_1.3-6 ## [67] fastmap_1.1.0 utf8_1.2.2 fastmatrix_0.4-1245 ## [70] semver_0.2.0 shape_1.4.6 readr_2.1.3 ## [73] stringi_1.7.12 parallel_4.2.2 Rcpp_1.0.10 ## [76] vctrs_0.5.2 tidyselect_1.2.0 xfun_0.36 1.4 Generalized Model at a Glance The general model underlying McMasterPandmic’s flexible engine and interface based on a discrete time compartmental model. \\[ s_{i,t+1} = s_{i,t} + \\underbrace{\\sum_j M_{ji,t} s_{j,t}}_{\\text{inflow}} - \\underbrace{s_{i,t} \\sum_j M_{ij,t} {\\mathcal I}_{ij}}_{\\text{outflow}} \\] where, \\(s_{i,t}\\) is the state of the \\(i\\)th compartment at time \\(t\\) \\(M_{ij,t}\\) is the per-capita rate of flow from compartment \\(i\\) to compartment \\(j\\) at time \\(t\\) \\({\\mathcal I}_{ij}\\in\\{0,1\\}\\) indicates whether or not individuals should be removed from compartment \\(i\\) after flowing to compartment \\(j\\) The per-capita rates, \\(M_{ij,t}\\), can be any expression involving only sums and products of any of the following at time \\(t\\): State of any compartment Model parameter, which can be time-varying – see the Model of Piece-Wise Time-Variation for details Complements of any of the above (i.e. \\(1-x\\)) Inverses of any of the above (i.e. \\(1/x\\)) 1.5 Vision and Direction Our philosophy is that modellers should spend more time thinking about modelling and less time coding, troubleshooting, and waiting for computations to finish. To realize this vision we work on features that help improve at least some of the following user stories. Fast As a modeller I want faster forecasting and calibration So that I have the time to iteratively refine my models Rigorous As a scientist I want to use rigorous statistical techniques for fitting mechanistic models to data So that I can produce defensible descriptions of the processes that I am modelling Functionality-rich As a modeller I need to use software that provides an extensive set of modelling capabilities So that I can address specific and changing public health needs, which building on what I have done before Numerically-stable As a modeller I need software that ideally hides the details of scientific computing from me (e.g. I don’t need to worry about things like convergence) and at least provides informative and actionable messages about numerical issues So that I can focus on the biology and public-health implications Editable As a modeller I want to build complex models out of simpler – easier to understand – modular sub-models So that I can more easily modify the structure of my model as public health needs change Versionable As a modeller I want to save my model definitions in format that is both human-readable and computer-consumable So that I can easily see the differences between two model versions and easily review the details of models used for past forecasts Extensible As a developer I want to be able to quickly add a new modelling capability So that I can support public health modellers in as timely a manner as possible The stories at the start of this list have been more fully realized in the existing software, and those at the bottom are more aspirational. This roadmap describes our current thoughts on what we should do next to address these five stories in as complete a manner as possible. "],["model-initialization.html", "2 Model Initialization 2.1 Initial Parameter Vector 2.2 Initial State Vector 2.3 Start and End Date 2.4 Next Steps", " 2 Model Initialization Before one may define the dynamics of their compartmental model they must initialize it using the flexmodel function. Here we describe each of the basic and required arguments to flexmodel and how to set them. This function allows one to define many details of the model, but in this chapter we cover just the requirements. Parameter vector State vector Start and end dates Here is a simple SIR model example. sir = flexmodel( params = c(beta = 0.1, gamma = 0.01, N = 100), state = c(S = 99, I = 1, R = 0), start_date = &quot;2020-03-11&quot;, end_date = &quot;2020-12-01&quot; ) ## as(&lt;matrix&gt;, &quot;dgTMatrix&quot;) is deprecated since Matrix 1.5-0; do as(as(as(., &quot;dMatrix&quot;), &quot;generalMatrix&quot;), &quot;TsparseMatrix&quot;) instead To learn more about these options, please keep reading this chapter. To continue building this simple SIR model, please move on to the next chapter, where you can define Flow Between States. 2.1 Initial Parameter Vector The parameter vector contains the following kinds of information. State transition rates or parameters determining them (e.g. transmission rate, \\(\\beta\\)) Initial numbers of individuals in a compartment or group of compartments (e.g. initial number of exposed individuals, \\(E_0\\)) Data processing parameters to make observed and simulated time-series more comparable (e.g. fraction of incidence reported as positive tests, \\(c_\\text{prop}\\)) In its simplest form these parameters can be specified as a standard named numeric vector. We used this approach above in our SIR example, and this parameter vector can be extracted from the model. pars_base_sim(sir) ## beta gamma N ## 1e-01 1e-02 1e+02 McMasterPandemic also has a special params_pansim object class for representing parameters. These objects come with descriptions of the meaning of each parameter. An example of this params_pansim format can be explored with the following command. rmarkdown::paged_table(describe_params(read_params(&#39;ICU1.csv&#39;))) See the McMasterPandemic getting started vignette for more info on params_pansim objects. 2.2 Initial State Vector The state vector is used to declare the names of the state variables. In the SIR example above we did this via a named numeric vector, and these names become the names of the initial state vector. state_init(sir) ## S I R ## 99 1 0 The numbers in this vector can be used as initial values in simulations, but often the initial values will depend on the parameters (see do_make_state TODO). In these cases where the initial state is computed as opposed to specified, the state argument to flexmodel can just be character vector giving the names of the state variables. Classic McMasterPandemic also has a state_pansim object type (TODO: describe). 2.3 Start and End Date The simulation model takes a step every day. The start_date and end_date arguments give start and end of these simulations. The format of these dates can be supplied in any format that is accepted by as.Date without any formatting options. 2.4 Next Steps Models can be initialized with more complex features including time-varying parameters, hazard steps, and model linearization for computing state vectors that lead to greater stability (TODO: link to chapters/sections). But before getting to these complexities there is something more important: definition of the flows of individuals amongst the states (TODO: link to next chapter). "],["flow-between-states.html", "3 Flow Between States 3.1 State Flows 3.2 Flow Matrix 3.3 Rate Matrix 3.4 Rate Matrix Dependence on State Variables and Parameters 3.5 Connections with Classic McMasterPandemic 3.6 Topological Sort", " 3 Flow Between States Here we describe the definition of the basic model of flows among states. Later chapters describe extensions to this basic model, both implemented (TODO) and unimplemented (TODO). The per-capita rate of flow between any two states can be defined using the add_rate function. sir = (sir %&gt;% add_rate(&quot;S&quot;, &quot;I&quot;, ~ (I) * (beta) * (1/N)) %&gt;% add_rate(&quot;I&quot;, &quot;R&quot;, ~ (gamma)) ) The first add_rate function says that on each simulated day, individuals flow from the S box to the I box at a rate equal to the product of I, beta, and 1/N. This rate is a per-capita rate, and so the flow of individuals from S to I is S times the rate. Similarly, the second add_rate function says that I times gamma individuals flow from I to R every simulated day. Here are the rules of these rate formulas (although these can be relaxed to some degree using techniques covered in later chapters). both state variables and parameters can be referred to by name as variables in the formulas variables must be encapsulated with parentheses variables can be converted to their inverse (1/x) or complement (1-x) variables, their inverses, and their complements can be combined using + and * operators Examples of valid rate formulas for this model include: (1-gamma) * (S) + (gamma) (1/I) (beta) * (gamma) + (beta) * (1/N) * (1-gamma) Examples of invalid rate formulas include: 1-gamma – no parentheses around this complement beta * gamma – no parentheses around variables (but this can be addressed using struc objects – TODO: link to these) ((S) + (R)) * (beta) – general grouping parentheses and common factors are not allowed (but this can be addressed using struc objects or intermediate computations – TODO: link to these) (E) * (beta) – the variable E is in neither the parameter nor state variable By specifying these rates, we now have a difference between the initial and final state vector. state_init(sir) ## S I R ## 99 1 0 state_final(sir) ## S I R ## 0.01240091 12.18596876 87.80163033 The remainder of this chapter describes the theory behind these rates, and clarifies what they mean. To start using this simple SIR model, please move on the the next chapter where you will learn how to do Simulation and explore epidemic trajectories. 3.1 State Flows The numbers of individuals in each compartment is stored in the state vector, \\(\\mathbf{s}\\), which contains one element for each compartment. At each time step, \\(t\\), the state vector is given by \\(\\mathbf{s}(t)\\). The relationship between the state vector at successive time steps is given by the following. \\[ \\mathbf{s}(t+1) = \\mathbf{s}(t) + \\mathbf{f}^{\\text{in}}(t) - \\mathbf{f}^{\\text{out}}(t) \\] where \\(\\mathbf{f}^{\\text{in}}\\) and \\(\\mathbf{f}^{\\text{out}}\\) are the inflow and outflow vectors. Continuing our concrete SIR model example, individuals flow from a box of susceptible individuals to infected to recovered individuals. \\[ S(t+1) = S(t) - \\frac{\\beta I(t)}{N}S(t) \\] \\[ I(t+1) = I(t) + \\frac{\\beta I(t)}{N}S(t) - \\gamma I(t) \\] \\[ R(t+1) = R(t) + \\gamma I(t) \\] where \\(\\beta\\), \\(\\gamma\\), and \\(N\\) are the transmission rate and population size parameters. In this model the inflow to the \\(S\\) box is zero and the outflow from \\(R\\) is also zero. Therefore we can express this model in general terms as the following. \\[ \\mathbf{s} = \\begin{bmatrix} S \\\\ I \\\\ R \\end{bmatrix} \\] \\[ \\mathbf{f}^{\\text{in}} = \\begin{bmatrix} 0 \\\\ \\frac{\\beta I S}{N} \\\\ \\gamma I \\end{bmatrix} \\] \\[ \\mathbf{f}^{\\text{out}} = \\begin{bmatrix} \\frac{\\beta I S}{N} \\\\ \\gamma I \\\\ 0 \\end{bmatrix} \\] 3.2 Flow Matrix Note that the outflow from \\(S\\) and inflow to \\(I\\) in the previous example has an identical magnitude. This is a common pattern in compartmental models. Many outflows are balanced perfectly by an associated inflow, to model individuals flowing from one compartment to another. McMasterPandemic assumes this balancing of flows to be the default situation, and therefore expresses both inflows and outflows in terms of an \\(n\\) by \\(n\\) flow matrix, \\(\\mathbf{F}\\), that only requires specifying a single expression for each inflow-outflow pair. The element in the \\(i\\)th row and \\(j\\)th column of the flow matrix gives the flow from state \\(i\\) to state \\(j\\). The default inflow and outflow vectors can therefore be computed as the column sums and row sums respectively. Continuing the SI model example, we have the following flow matrix. \\[ \\mathbf{F} = \\begin{bmatrix} 0 &amp; \\frac{\\beta I}{N}S &amp; 0 \\\\ 0 &amp; 0 &amp; \\gamma I \\\\ 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} \\] There are times however where one wants a particular flow from one state to another to include only the inflow component and not the outflow. For example in cases where death removes individuals from the population. We consider this and other examples of asymmetric flow in later chapters (TODO). 3.3 Rate Matrix In modelling it is often more convenient to define per-capita rates of flow between compartments rather than total flow. The rate matrix, \\(\\mathbf{M}\\), contains these per-capita rates. The elements, \\(F_{ij}\\), of the flow matrix can be computed from the rate matrix and the state vector as follows. \\[ F_{ij} = M_{ij}s_i \\] The rate matrix for the SI model is given by the following expression. \\[ \\mathbf{M} = \\begin{bmatrix} 0 &amp; \\frac{\\beta I}{N} &amp; 0 \\\\ 0 &amp; 0 &amp; \\gamma \\\\ 0 &amp; 0 &amp; 0 \\end{bmatrix} \\] The elements of the rate matrix are determined by expressions involving elements of the state vector and parameters, which we collect into a paramter vector, \\(\\mathbf{\\theta}\\). For the SI model \\(\\mathbf{\\theta}\\) contains two parameters. \\[ \\mathbf{\\theta} = \\begin{bmatrix} \\beta \\\\ \\gamma \\\\ N \\end{bmatrix} \\] 3.4 Rate Matrix Dependence on State Variables and Parameters Currently it is not possible to specify elements of the rate matrix as arbitrary arithmetic expressions involving state variables and parameters – although we plan to add this functionality. However, there is a reasonable degree of flexibility. Each element of the rate matrix can be any expression that obeys the following rules. Any element, \\(x\\), of either the parameter or state vector can be used to define a factor in one of the following three forms. Identity: \\(x\\) Complement: \\(1-x\\) Inverse: \\(1/x\\) We collect these user-defined factors into a factor vector, \\(\\mathbf{y}\\). Factors can be repeated in \\(\\mathbf{y}\\) if required. Any number of factors can be multiplied together using * to produce a product. Any number of factors and products can be added together using +. There is the following higher level nested structure associated with the factor vector, \\(\\mathbf{y}\\). All factors associated with the, \\(i\\)th, non-zero rate matrix element, \\(M_{(i)}\\), are grouped together in a contiguous block within \\(\\mathbf{y}\\) Within the \\(i\\)th block, all factors associated with the \\(j\\)th product (\\(j = 1 ... n_i\\)) in that block are grouped together in a contiguous sub-block Within the \\(i,j\\)th sub-block, all factors are given an index, \\(k = 1 ... m_{ij}\\) With these definitions, the dependence of any non-zero rate matrix element on the parameters and state variables is given by the following expression. \\[ M_{(i)} = \\sum_{j=1}^{n_i} \\prod_{k=1}^{m_{ij}} y_{ijk} \\] where \\(y_{ijk}\\) is the \\(k\\)th factor associated with the \\(j\\)th product associated with the \\(i\\)th non-zero rate matrix element. from to n-fctrs n-prdcts n-vrbls state-dependent time-varying sum-dependent S I 3 1 3 TRUE FALSE FALSE I R 1 1 1 FALSE FALSE FALSE McMasterPandemic is designed to be modular and allow multiple definitions of valid expressions for the rate matrix. In later chapters we describe this possibility (TODO). 3.5 Connections with Classic McMasterPandemic params &lt;- read_params(&quot;ICU1.csv&quot;) classic_macpan = make_base_model( params = params, state = NULL, start_date = &quot;2021-09-10&quot;, end_date = &quot;2021-10-10&quot; ) knitr::kable(rate_summary(classic_macpan, include_parse_info = FALSE)) from to E_to_Ia E Ia E_to_Ip E Ip Ia_to_R Ia R Ip_to_Im Ip Im Ip_to_Is Ip Is Im_to_R Im R Is_to_H Is H Is_to_ICUs Is ICUs Is_to_ICUd Is ICUd Is_to_D Is D ICUs_to_H2 ICUs H2 ICUd_to_D ICUd D H2_to_R H2 R H_to_R H R Is_to_X Is X S_to_E S E 3.6 Topological Sort The ordering of compartments with which individuals flow can be determined using the topological_sort function, provided that the graph is a DAG (i.e. there are no loops such as waning immunity). So for example the topologically sorted ordering of the classic McMasterPandemic model is given by the following. topological_sort(classic_macpan) ## [1] &quot;S&quot; &quot;V&quot; &quot;E&quot; &quot;Ia&quot; &quot;Ip&quot; &quot;Im&quot; &quot;Is&quot; &quot;H&quot; &quot;ICUs&quot; &quot;ICUd&quot; ## [11] &quot;X&quot; &quot;H2&quot; &quot;D&quot; &quot;R&quot; This can be used to order categorical variables for sorting tables and arranging plot facets. knitr::kable(classic_macpan %&gt;% rate_summary(include_parse_info = FALSE) %&gt;% mutate(from = factor(from, topological_sort(classic_macpan))) %&gt;% arrange(from) ) from to S_to_E S E E_to_Ia E Ia E_to_Ip E Ip Ia_to_R Ia R Ip_to_Im Ip Im Ip_to_Is Ip Is Im_to_R Im R Is_to_H Is H Is_to_ICUs Is ICUs Is_to_ICUd Is ICUd Is_to_D Is D Is_to_X Is X H_to_R H R ICUs_to_H2 ICUs H2 ICUd_to_D ICUd D H2_to_R H2 R model = classic_macpan state_nms = base::setdiff(topological_sort(model), c(&quot;X&quot;, &quot;V&quot;)) nodes = data.frame( id = state_nms, label = state_nms, title = state_nms, physics = FALSE) visNetwork( nodes, select(rate_summary(model), from, to) %&gt;% mutate(arrows = &quot;to&quot;)) %&gt;% #visLegend() %&gt;% #visLayout() %&gt;% visInteraction(zoomSpeed = 0.1) %&gt;% visPhysics(stabilization = TRUE) %&gt;% visHierarchicalLayout(direction = &quot;LR&quot;) "],["simulation.html", "4 Simulation 4.1 Observation Error", " 4 Simulation All previous chapters were concerned with defining a compartmental model. In this chapter we switch to getting results from a defined model. Once a model object is defined, it can be used to generate simulations using the simulation_history function. simulation_history(sir) The output contains a column for the simulation date, one column for each state variable (S, I and R in this case), and one column for every time-varying rate (S_to_I). The names of the time-varying rates are always of the form {from_state}_to_{to_state}. The reason why S_to_I is time-varying in this model is that it depends on a state variable, I, which is itself varying at every time-step. The rate_summary function can be used to remind us of this fact. (sir %&gt;% rate_summary(include_formula = TRUE) %&gt;% select(from, to, formula) ) ## from to formula ## S_to_I S I (I) * (beta) * (1/N) ## I_to_R I R (gamma) We see here that S_to_I does indeed depend on I in its formula, whereas I_to_R depends only on a parameter, gamma. Note that the above command uses the tidyverse-style pipe, %&gt;%, operator and another tidyverse function, select. This illustrates a general philosophy of McMasterPandemic, which is that we try to make the outputs plug into other existing and popular tools rather than reinvent existing functionality for a narrower purpose. For example, the rate_summary function returns a data frame that can be manipulated by other data frame manipulation tools. We can plug into other existing and popular tools to make a plot of the simulated epidemic trajectory. (sir %&gt;% simulation_history %&gt;% select(-S_to_I) %&gt;% pivot_longer(-Date, names_to = &quot;State&quot;, values_to = &quot;Population&quot;) %&gt;% mutate(State = factor(State, levels = topological_sort(sir))) %&gt;% ggplot + geom_line(aes(Date, Population, colour = State)) ) There are a few places you can go from here: Learn how to fit a model to observed data through Calibration Learn how to modify the values of parameters in simulation time using Time Varying Parameters Keep reading to learn about simulating with Observation Error 4.1 Observation Error sir_with_obs_err = (sir %&gt;% update_params(c( nb_disp_S = 1e4, nb_disp_I = 1e4, nb_disp_R = 1e4 )) %&gt;% update_error_dist( S ~ negative_binomial(&quot;nb_disp_S&quot;), I ~ negative_binomial(&quot;nb_disp_I&quot;), R ~ negative_binomial(&quot;nb_disp_R&quot;) ) ) set.seed(1L) (sir_with_obs_err %&gt;% simulation_history(obs_error = TRUE) %&gt;% select(Date, S, I, R) %&gt;% pivot_longer(-Date, names_to = &quot;var&quot;, values_to = &quot;value&quot;) %&gt;% rename(date = Date) %&gt;% mutate(var = factor(var, levels = topological_sort(sir))) %&gt;% ggplot + facet_wrap(~ var) + geom_point(aes(date, value)) ) "],["calibration.html", "5 Calibration 5.1 Calibrating with Observation Error 5.2 Loss Function Theory", " 5 Calibration Sometimes it is possible to obtain observed time-series data from an epidemic that one is modelling. It is natural to want to use such data to refine parameter values. This process of refinement is called calibration. To illustrate McMasterPandemic calibration functionality, we are going to calibrate to a synthetic dataset generated by the model we are calibrating. In the last chapter we showed how to simulate from a simple SIR model. Here we simulate from this model and then manipulate the resulting data into a form that could be used for calibration. Although this functionality can be used to fit any number of model parameters to any number of observed time-series, here we generate a single time-series of the numbers of infected individuals. synthetic_data = (sir %&gt;% simulation_history(include_initial_date = FALSE) %&gt;% select(Date, I) %&gt;% pivot_longer(-Date, names_to = &quot;var&quot;, values_to = &quot;value&quot;) %&gt;% rename(date = Date) ) When fitting data to a model, a specific format must be used. In particular there must be exactly the following three columns. date – date associated with each observation var – name of the state variable to compare value – observed value to compare with the simulated state variable In this particular case there is only a single state variable used, but this need not be the case. We next update the model object so that it contains two new ingredients: (1) the observed time-series data and (2) information on what parameters to fit and how to fit them. sir_to_calibrate = (sir %&gt;% update_observed(synthetic_data) %&gt;% update_opt_params( log_beta ~ log_flat(0), log_nb_disp_I ~ log_normal(0, 5) ) ) The observed time-series data are simply added via the update_observed function. The information of what parameters to fit gets passed to update_opt_params. This information is provided using two-sided formulas for each parameter to be optimized. The information on what parameter to optimize appears on the left-hand-side of the formula (i.e. to the left of the tilde). Here we optimize the transmission rate parameter, beta, because the numbers of infected individuals in our time-series will be most informative about this parameter. The prefix log_ is used to indicate that the parameter should get passed to the objective function on the log scale. This transformation is useful because it keeps the transmission rate positive. If no transformation is desired, then simply beta should appear on the left-hand-side. The following additional transformations are available: logit_, log10, cloglog_, inverse_. The information on what prior distribution (or regularization function) to use, as well as initial values for the optimizer, are provided on the right-hand-side of the formula. Currently, the transformation (i.e. log_ in this case) must match the left-hand-side, although we plan to remove this restriction so that the scale on which the prior density is evaluated can be different from the scale on which the parameter is passed to the objective function. There are only two prior distributions available currently: flat and normal. The flat prior is an improper flat distribution, providing no regularization. The only hyperparameter to the flat prior is the initial value for the optimizer on the transformed scale. The normal prior is the normal distribution with two hyperparameters, mean and standard deviation. The mean is also taken as the starting value. Note that there is another parameter that we need to describe that we did not include in our original definition of the model: nb_disp_I. This is the dispersion parameter of the negative binomial distribution used to model errors in the fit of the data to the simulated trajectories. We have used a log_normal prior here instead of a log_flat prior, because negative binomial dispersion parameters have a tendency to get very large in synthetic data cases like this where there is very little error – large dispersion parameters indicate consistency with Poisson error. This negative binomial parameter has been added automatically to the params element of the model when the observed data are added. pars_base_sim(sir_to_calibrate) ## beta gamma N nb_disp_I ## 1e-01 1e-02 1e+02 1e+00 But note how the parameters in the original model did not contain this parameter. pars_base_sim(sir) ## beta gamma N ## 1e-01 1e-02 1e+02 The sir_to_calibrate object can be calibrated using one of the optimizers in R that have been wrapped for use with flexmodels. There are currently two options: nlminb_flexmodel and optim_flexmodel. The difference between the two is that the former uses second-derivative information whereas the latter does not; they both use first-derivative information. sir_calibrated = calibrate_flexmodel(sir_to_calibrate) The result of these optimization functions is another model object containing additional information. convergence_info(sir_calibrated) ## $par ## log_beta log_nb_disp_I ## -2.302585 9.365837 ## ## $value ## [1] 677.25 ## ## $counts ## function gradient ## 47 18 ## ## $convergence ## [1] 0 ## ## $message ## NULL ## ## $hessian ## [,1] [,2] ## [1,] 9.040137e+03 -8.911629e-06 ## [2,] -2.095180e-05 4.134060e-01 ## ## $maxgrad ## [1] 0.002784678 ## ## $eratio ## [1] 4.573006e-05 This element is the object returned by the wrapped optimizer (nlminb in this case) – it can provide useful information about how well the optimization worked. In this case we see convergence, but this need not be true. Refer to documentation for nlminb and optim for help on interpreting these outputs. We can now look at the parameter vector, which has been updated to reflect the calibration. pars_base_sim(sir_calibrated) ## beta gamma N nb_disp_I ## 9.999997e-02 1.000000e-02 1.000000e+02 1.168238e+04 Fitted flexmodel objects have a fitted method that can be used to compare the fits with the observed values. (sir_calibrated %&gt;% fitted %&gt;% ggplot() + geom_point(aes(date, value)) + geom_line(aes(date, value_fitted), colour = &#39;red&#39;) ) As expected, the fit is exact because the model that was fitted was also used to simulate the data. But this perfect is not very realistic. The next section, Calibrating with Observation Error, illustrates calibration to noisy data. 5.1 Calibrating with Observation Error To illustrate fitting to data with observation error we simulate some noisy observations of numbers of individuals in the I compartment, using the simulation model we made in the Observation Error section. set.seed(1L) noisy_data = (sir_with_obs_err %&gt;% simulation_history(include_initial_date = FALSE, obs_error = TRUE) %&gt;% select(Date, I) %&gt;% pivot_longer(-Date, names_to = &quot;var&quot;, values_to = &quot;value&quot;) %&gt;% rename(date = Date) ) ggplot(noisy_data) + geom_point(aes(date, value)) We can fit these data to a model following the approaches in the Calibration section. sir_obs_err_to_calibrate = (sir_with_obs_err %&gt;% update_observed( noisy_data, loss_params = McMasterPandemic:::loss_params(sir_with_obs_err) ) %&gt;% update_opt_params(log_beta ~ log_normal(-1, 0.5) ,log_nb_disp_I ~ log_normal(10, 1) ) ) This process starts by updating the simulation model with observed data and specifying what parameters to optimize. We may pass this model to the optimizer, and indeed do achieve convergence. sir_obs_err_calibrated = calibrate_flexmodel(sir_obs_err_to_calibrate) print(class(sir_obs_err_calibrated)) ## [1] &quot;flexmodel_bbmle&quot; &quot;flexmodel_calibrated&quot; &quot;flexmodel&quot; convergence_info(sir_obs_err_calibrated) ## $par ## log_beta log_nb_disp_I ## -2.300352 9.991748 ## ## $value ## [1] 801.6395 ## ## $counts ## function gradient ## 41 10 ## ## $convergence ## [1] 0 ## ## $message ## NULL ## ## $hessian ## [,1] [,2] ## [1,] 8.874538e+03 0.001175772 ## [2,] 1.166795e-03 0.992192386 ## ## $maxgrad ## [1] 3.803997e-06 ## ## $eratio ## [1] 0.0001118022 Not only do we achieve convergence but we also achieve a good fit, which is not surprising given that we are fitting the same model that was used to simulate the data. (fitted(sir_obs_err_calibrated) %&gt;% ggplot + geom_line(aes(date, value_fitted)) + geom_point(aes(date, value)) ) 5.2 Loss Function Theory Let \\(l_{\\psi_i}\\left(x_i(\\theta); y_i\\right)\\) be a loss function where \\(x_i(\\theta)\\) is a simulated element of the history matrix, \\(y_i\\) is an associated observed data point, and \\(\\psi_i\\) is a vector of loss function parameters. Note that we write the simulation values as functions of \\(\\theta\\) to indicate their dependence on parameters. Every element \\(i\\) that belongs to the same column of the history matrix has the same value for \\(\\psi_i\\), but to simplify notation \\(\\psi\\) is sub-scripted by \\(i\\). Let \\(r_{\\phi_j}(\\theta_j)\\) be an optional regularization function for each parameter \\(\\theta_j\\) being optimized, where \\(\\phi_j\\) is a vector of regularization function parameters associated with parameter \\(j\\). The objective function is then given by the following. \\[ L_{\\psi, \\phi}(\\theta; y) = \\sum_i l_{\\psi_i}\\left(x_i(\\theta); y_i\\right) + \\sum_j r_{\\phi_j}(\\theta_j) \\] Currently the only objective function that is offered is the negative log negative binomial density, but the infrastructure we build assumes that other loss functions will be allowed in the future. Similarly the only regularizing function that is available is the negative log normal density. Each parameter, \\(\\theta_j\\), can be optionally passed into the objective function on a transformed scale. These transformations allow users to enforce limits on the domain of the parameter space (e.g. a logit transformation will keep parameter values between 0 and 1). The regularization functions are applied on the transformed scale, but the elements of the rate matrix (and therefore the simulations, \\(x\\)) are computed using the parameters on their original scale. Therefore, we have the following ordering of operations. Parameter, \\(\\theta_j\\), is passed in to the objective function on the transformed scale, \\(f(\\theta_j)\\) The regularization function, \\(r_{\\phi_j}(\\theta_j)\\), is computed and saved The inverse transformation is applied to the parameter, \\(\\theta_j\\), and the result is used to overwrite the previous value in the c++ params vector The simulations are made The objective function, \\(L\\), is computed, and this computation includes adding the saved values of the regularization functions The objective function, \\(L\\), is returned by the c++ function objective_function 5.2.1 Negative Binomial \\[ \\frac{\\Gamma(x+k)}{\\Gamma(k) x!} \\left(\\frac{k}{k + \\mu}\\right)^k \\left(\\frac{\\mu}{k + \\mu}\\right)^x \\] \\[ \\log\\Gamma(x+k) - \\log\\Gamma(k) - \\log(x!) + k \\log\\left(\\frac{k}{k + \\mu}\\right) + x\\log\\left(\\frac{\\mu}{k + \\mu}\\right) \\] "],["convergence.html", "6 Convergence", " 6 Convergence In the last chapter we showed how to fit a simple SIR model to data, and things went relatively smoothly. Now we modify the fitting problem just slightly to illustrate how things can get more challenging pretty quickly. In particular we simulate all three state variables and give them different levels of observation error by specifying different values for the negative binomial dispersion parameter. set.seed(1L) more_noisy_data = (sir_with_obs_err %&gt;% update_params(c( nb_disp_S = 0.1, nb_disp_I = 1e4, nb_disp_R = 1 )) %&gt;% simulation_history(include_initial_date = FALSE, obs_error = TRUE) %&gt;% select(-S_to_I) %&gt;% pivot_longer(-Date, names_to = &quot;var&quot;, values_to = &quot;value&quot;) %&gt;% mutate(var = factor(var, topological_sort(sir))) %&gt;% rename(date = Date) ) (ggplot(more_noisy_data) + facet_wrap(~var, scales = &#39;free&#39;) + geom_point(aes(date, value)) ) With these new simulated data we update the flexmodel object that we were previously using for calibration with the more challenging noisy data. Note also that we declare more dispersion parameters to be optimized, because the data now include all three compartments. sir_harder_to_calibrate = (sir_to_calibrate %&gt;% reset_error_dist %&gt;% update_observed(more_noisy_data) %&gt;% update_opt_params( log_beta ~ log_flat(0), log_nb_disp_S ~ log_flat(0), log_nb_disp_I ~ log_flat(0), log_nb_disp_R ~ log_flat(0) ) ) Fitting this model using the defaults results in the following errors from the optimizer. sir_hard_attempt_1 = calibrate_flexmodel(sir_harder_to_calibrate) ## Error in optim(par = c(log_beta = 0, log_nb_disp_S = 0, log_nb_disp_I = 0, : ## initial value in &#39;vmmin&#39; is not finite convergence_info(sir_hard_attempt_1) ## [1] &quot;Error in optim(par = c(log_beta = 0, log_nb_disp_S = 0, log_nb_disp_I = 0, : \\n initial value in &#39;vmmin&#39; is not finite\\n&quot; ## attr(,&quot;class&quot;) ## [1] &quot;try-error&quot; ## attr(,&quot;condition&quot;) ## &lt;simpleError in optim(par = c(log_beta = 0, log_nb_disp_S = 0, log_nb_disp_I = 0, log_nb_disp_R = 0), fn = function (p) { if (browse_obj) browser() l &lt;- relist2(p, template) names(p) &lt;- nstart[order(oo)] l[nfix] &lt;- fixed if (vecpar) { l &lt;- namedrop(l[nfull]) l &lt;- unlist(l) args &lt;- list(l) args &lt;- c(list(l), args.in.data) } else { args &lt;- c(l, args.in.data) } if (namedrop_args) args &lt;- namedrop(args) do.call(&quot;minuslogl&quot;, args)}, method = &quot;BFGS&quot;, hessian = FALSE, gr = function (p) { if (browse_obj) browser() l &lt;- relist2(p, template) names(p) &lt;- nstart[order(oo)] l[nfix] &lt;- fixed if (vecpar) { l &lt;- namedrop(l[nfull]) l &lt;- unlist(l) args &lt;- list(l) args &lt;- c(list(l), args.in.data) } else { args &lt;- c(l, args.in.data) } v &lt;- do.call(&quot;gr&quot;, args) if (is.null(names(v))) { if (length(v) == length(l) &amp;&amp; !is.null(tt &lt;- names(l))) { vnames &lt;- tt } else if (length(v) == length(p) &amp;&amp; !is.null(tt &lt;- names(p))) { vnames &lt;- tt } else if (!is.null(tt &lt;- parnames(minuslogl))) { vnames &lt;- tt } else vnames &lt;- names(formals(minuslogl)) if (length(vnames) != length(v)) stop(&quot;name/length mismatch in gradient function&quot;) names(v) &lt;- vnames } return(v[!names(v) %in% nfix])}, control = list(), lower = -Inf, upper = Inf): initial value in &#39;vmmin&#39; is not finite&gt; sir_hard_attempt_2 = calibrate_flexmodel( sir_harder_to_calibrate, optimizer = &#39;nlminb&#39; ) ## Warning in nlminb(start = start, objective = objectivefunction, hessian = NULL, ## : NA/NaN function evaluation ## Warning in nlminb(start = start, objective = objectivefunction, hessian = NULL, ## : NA/NaN function evaluation ## Warning in nlminb(start = start, objective = objectivefunction, hessian = NULL, ## : NA/NaN function evaluation ## Warning in nlminb(start = start, objective = objectivefunction, hessian = NULL, ## : NA/NaN function evaluation ## Warning in nlminb(start = start, objective = objectivefunction, hessian = NULL, ## : NA/NaN function evaluation ## Warning in nlminb(start = start, objective = objectivefunction, hessian = NULL, ## : NA/NaN function evaluation ## Warning in nlminb(start = start, objective = objectivefunction, hessian = NULL, ## : NA/NaN function evaluation ## Warning in bbmle::mle2(obj_fun$fn, start_par, gr = obj_fun$gr, parnames = ## names(start_par), : couldn&#39;t invert Hessian convergence_info(sir_hard_attempt_2) ## $par ## log_beta log_nb_disp_S log_nb_disp_I log_nb_disp_R ## 0 0 0 0 ## ## $objective ## [1] Inf ## ## $convergence ## [1] 0 ## ## $iterations ## [1] 1 ## ## $evaluations ## function gradient ## 2 4 ## ## $message ## [1] &quot;X-convergence (3)&quot; ## ## $hessian ## [,1] [,2] [,3] [,4] ## [1,] NaN NaN NaN NaN ## [2,] NaN NaN NaN NaN ## [3,] 13.64742 0 102.8402 0.0000 ## [4,] 13.27857 0 0.0000 189.5047 ## ## $maxgrad ## [1] NaN ## ## $eratio ## [1] NA sir_hard_attempt_3 = (sir_harder_to_calibrate %&gt;% update_opt_params( log_beta ~ log_flat(-1), log_nb_disp_S ~ log_flat(0), log_nb_disp_I ~ log_flat(0), log_nb_disp_R ~ log_flat(0) ) %&gt;% calibrate_flexmodel ) convergence_info(sir_hard_attempt_3) ## $par ## log_beta log_nb_disp_S log_nb_disp_I log_nb_disp_R ## -2.3075737 -2.1004227 9.0642536 -0.1010736 ## ## $value ## [1] 2294.749 ## ## $counts ## function gradient ## 75 28 ## ## $convergence ## [1] 0 ## ## $message ## NULL ## ## $hessian ## [,1] [,2] [,3] [,4] ## [1,] 1.002927e+04 -19.31947 -0.056975984 -5.624261 ## [2,] -1.931947e+01 39.92026 0.000000000 0.000000 ## [3,] -5.696362e-02 0.00000 0.003400036 0.000000 ## [4,] -5.624261e+00 0.00000 0.000000000 129.828358 ## ## $maxgrad ## [1] 0.005206376 ## ## $eratio ## [1] 3.389777e-07 sir_hard_attempt_4 = profile(opt_obj(sir_hard_attempt_3)) ## Profiling has found a better solution,so original fit had not converged: ## (new deviance=3633, old deviance=4589, diff=-956.8) ## Returning better fit ... sir_hard_attempt_4@details ## $par ## log_beta log_nb_disp_S log_nb_disp_R ## -2.2471694 -2.1075732 -0.1006872 ## ## $value ## [1] 1816.368 ## ## $counts ## function gradient ## 84 9 ## ## $convergence ## [1] 0 ## ## $message ## NULL ## ## $hessian ## [,1] [,2] [,3] ## [1,] NA NA NA ## [2,] NA NA NA ## [3,] NA NA NA ## ## $maxgrad ## [1] 574.4543 plot(slice(sir_hard_attempt_4)) ## log_beta ## log_nb_disp_S ## log_nb_disp_I.log_nb_disp_I ## log_nb_disp_R TODO: plot profiles and slices TODO: add ability to use auto-diff hessian with bbmle (currently not even possible with optimizer = ‘nlminb’ because this is a bbmle::mle2 argument and bbmle::mle2 doesn’t allow use-supplied hessian functions, at least by default) TODO: add functionality to the package for updating starting values in a more convenient manner than update_opt_params. maybe even a way to modify the starting values based on a vector giving the argument to the objective function. this would allow one to chain together optimization runs. "],["time-varying-parameters.html", "7 Time Varying Parameters 7.1 Model of Piece-Wise Time-Variation 7.2 Calibrating Time-Variation Schedules", " 7 Time Varying Parameters Any parameter in a McMasterPandemic model can be scheduled to vary in time. In this example we create a time-variation schedule that causes the transmission, beta, drop to very low levels on May 15. random_timevar = data.frame( Date = ymd(20200515), Symbol = &#39;beta&#39;, Value = 0.01, Type = &#39;abs&#39; ) random_timevar ## Date Symbol Value Type ## 1 2020-05-15 beta 0.01 abs sir_with_timevar = (sir %&gt;% update_piece_wise(random_timevar) %&gt;% update_error_dist( S ~ poisson(), I ~ poisson(), R ~ poisson() ) ) timevar_sims = (sir_with_timevar %&gt;% simulation_history(include_initial_date = FALSE, obs_error = TRUE) %&gt;% tidyr::pivot_longer(-Date, names_to = &quot;var&quot;) %&gt;% rename(date = Date) %&gt;% mutate(value = round(value)) %&gt;% filter(var %in% c(&quot;S&quot;, &quot;I&quot;, &quot;R&quot;)) ) (ggplot(timevar_sims) + geom_line(aes(date, value, colour = var)) ) Notice the abrupt break-point on May 15 that causes the numbers of infected individuals to decrease. We can easily compare the parameters at the beginning of the simulation with parameters at the end of the simulation. pars_base_sim(sir_with_timevar) ## beta gamma N ## 1e-01 1e-02 1e+02 pars_base_final(sir_with_timevar) ## beta gamma N ## 1e-02 1e-02 1e+02 See [The SIRV model] and Covid SEIR for other examples of the use of time-varying parameters in simulation models. There are a few places you can go from here: Keep reading to learn about the general Model of Piece-Wise Time-Variation that is used by McMasterPandemic Learn about Calibrating Time-Variation Schedules Learn how to forecast with time-variation schedules in order to explore what-if-scenarios Learn how to specify time-variation multipliers on the logit-scale for parameters that should be bound between zero and one TODO: Complex Time-Variation Schedules TODO: When log-linear models are developed there should be a pointer to their documentation here 7.1 Model of Piece-Wise Time-Variation A time-variation schedule is a data frame with one row for each date on which each parameter changes its value. This data frame has four columns that can be used to define the characteristics of each break-point. Date – Date on which a particular parameter changes its value Symbol – String giving the symbol representing the changing parameter Value – The numeric value used to change the value of the parameter, the effect of which depends on the value of the Type column Type – One of the following strings: \"abs\" – The Value column is the new value for the parameter on Date \"rel_orig\" – The Value column is multiplied by the original value of the changing parameter at the beginning of the simulation, to generate a new value for the parameter on Date \"rel_prev\" – The Value column is multiplied by the previous value of the changing parameter, to generate a new value for the parameter on Date \"rel_orig_logit\" – The Value column is added to the logit transform of the original value, and then the inverse logit transform is applied to this sum to generate a new value for the parameter on Date \"rel_prev_logit\" – The Value column is added to the logit transform of the previous value of the changing parameter, and then the inverse logit transform is applied to this sum to generate a new value for the parameter on Date Let \\(\\theta_t\\) be the focal parameter at time \\(t\\), let \\(\\theta_0\\) be the original value of \\(\\theta\\) at the beginning of the simulation, let \\(t = \\tau\\) be a time at which \\(\\theta\\) changes value, and let \\(\\nu_\\tau\\) be the number in the Value column associated with the breakpoint at \\(\\tau\\). The following table describes the different types of time variation. Time Variation Type Parameter Update Expression abs \\(\\theta_\\tau = \\nu_\\tau\\) rel_orig \\(\\theta_\\tau = \\theta_0 \\nu_\\tau\\) rel_prev \\(\\theta_\\tau = \\theta_{\\tau-1} \\nu_\\tau\\) rel_orig_logit \\(\\theta_\\tau = \\text{logit}^{-1}\\left(\\text{logit}(\\theta_0) + \\nu_\\tau\\right)\\) rel_prev_logit \\(\\theta_\\tau = \\text{logit}^{-1}\\left(\\text{logit}(\\theta_{\\tau-1}) + \\nu_\\tau\\right)\\) Once a time-variation data frame is produced it can get added to a model when it is created via the params_timevar argument of flexmodel, or by updating an existing flexmodel object using the update_piece_wise function. 7.2 Calibrating Time-Variation Schedules Entries in the Value column can be NA, indicating that these should be fitted using Calibration. When flagging time-variation values for calibration in this way, one must also provide information on any parameter transformations and prior distributions. Do provide this information, we use a technique similar to the one described in the Calibration chapter to specify transformations and prior distributions for parameters in the params element of flexmodel objects. In that chapter we used the add_opt_params function – here we use the add_opt_tv_params function (the tv stands for time-variation). To illustrate calibration of time-variation values, we mark for calibration the break-point on May 15 in our example above. calibrate_timevar = (random_timevar %&gt;% mutate(Value = NA) ) Then we update our model with the sir_with_timevar simulations to fit to, and specify how to optimize the parameters. sir_to_cal_tv = (sir_with_timevar %&gt;% update_observed(timevar_sims) %&gt;% update_piece_wise(calibrate_timevar) %&gt;% add_opt_params(log_beta ~ log_flat(-2)) %&gt;% add_opt_tv_params(tv_type = &quot;abs&quot; , log_beta ~ log_flat(-4) ) ) The key function here is add_opt_tv_params, which allows us to specify a flat prior on the log scale for fitting the time-variation values. It turns out that in this case we need to make one technical adjustment – see Simulated time-series close to zero for an explanation. sir_to_cal_tv$do_sim_constraint = TRUE With this sir_to_cal_tv object we can now fit this model to the simulated data. sir_cal_tv = calibrate_flexmodel(sir_to_cal_tv) The time-variation values before, during, and after optimization look as we would expect, given that we fitted to the same model that generated the data. c( before = pars_time_series(sir_with_timevar)$Value, during = pars_time_series(sir_to_cal_tv) $Value, after = pars_time_series(sir_cal_tv) $Value ) ## before during after ## 0.010000000 1.000000000 0.009242963 (sir_cal_tv %&gt;% fitted %&gt;% mutate(var = factor(var, topological_sort(sir_cal_tv))) %&gt;% ggplot + facet_wrap(~var) + geom_line(aes(date, value)) + geom_line(aes(date, value_fitted), colour = &#39;red&#39;) ) "],["other-variables.html", "8 Other Variables 8.1 Intermediate Results 8.2 Additional Variables in the Simulation History", " 8 Other Variables So far the only types of variables that we have discussed are parameters and state variables. In this chapter we cover all of the other kinds of variables. There are two basic kinds of other variables: (1) Intermediate Results and (2) Additional Variables in the Simulation History. The main difference between the two types is that the former can be used for more purposes than the latter. In particular, intermediate results can be used in expressions that define rate matrices whereas additional variables in the simulation history cannot. Conversely, all intermediate results get added to the simulation history. 8.1 Intermediate Results Sometimes the expression giving the rate of flow between two compartments is quite complex, or even just impossible to express in terms of just parameters and state variables given the restrictions described in the chapter on [Flows Between States]. In these cases, it is often convenient or even necessary to store intermediate combinations of parameters and state variables and then use these combinations in subsequent expressions for flow rates. There are three basic kinds of intermediate results: (1) sums of state variables and parameters, (2) more general expressions, called factrs, that combine state variables, parameters, and their sums, and (3) power laws involving any of these variables as base, exponent, and constant. 8.1.1 Sums of State Variables and Parameters One may save any sum of state variables and/or parameters to the model. In our SIR model for example, we specified the total population size in the parameter vector as N. However, we could compute this population size using the add_state_param_sum function. sir_with_sums = (flexmodel( params = c(beta = 0.1, gamma = 0.01), state = c(S = 99, I = 1, R = 0), start_date = &quot;2020-03-11&quot;, end_date = &quot;2020-12-01&quot; ) %&gt;% add_state_param_sum(&quot;N&quot;, &quot;S|I|R&quot;) %&gt;% add_rate(&quot;S&quot;, &quot;I&quot;, ~ (I) * (beta) * (1/N)) %&gt;% add_rate(&quot;I&quot;, &quot;R&quot;, ~ (gamma)) ) The first argument to the add_state_param_sum is just a name for the sum. Note that this name is used in the add_rate function that defines the flows from S to I. The second argument to the add_state_param_sum is a regular expression that is matched agains all parameter names and state variable names. Here we match any state variable with \"S|I|R\", which tells McMasterPandemic to add up all state variables and save the result in the variable called \"N\". See the Erlang SEIR example that uses a sum to save the total number of infected individuals across all I compartments in an Erlang-chain. See the BC Covid Omicron example that uses a sum to save the total number of individuals infected with different COVID strains. 8.1.2 Factrs First off, I’m sorry about the name factr. It is not a typo, I just don’t have the energy to change it to something better right now. factrs are simply a saved expression that follows the same rules for rates of [Flows Between States]. These factrs are named and can subsequently be used in rate expressions. The SIR model is not really complex enough to justify using factrs, but if we wanted to we could store the proportion of individuals that are in the I box as a factr and then use that factr in the expression for the rate from S to I. sir_with_factrs = (flexmodel( params = c(beta = 0.1, gamma = 0.01), state = c(S = 99, I = 1, R = 0), start_date = &quot;2020-03-11&quot;, end_date = &quot;2020-12-01&quot; ) %&gt;% add_state_param_sum(&quot;N&quot;, &quot;S|I|R&quot;) %&gt;% add_factr(&quot;Iprop&quot;, ~ (I) * (1/N)) %&gt;% add_rate(&quot;S&quot;, &quot;I&quot;, ~ (Iprop) * (beta)) %&gt;% add_rate(&quot;I&quot;, &quot;R&quot;, ~ (gamma)) ) See also the SI model example for a use of factrs that computes the equilibrium populations in each compartment. 8.1.3 Power Laws Intermediate results of the following functional form can be specified. \\[ y = y_0x^b \\] where \\(y\\) is the new intermediate result, and \\(y_0\\), \\(x\\), and \\(b\\) are parameters, state variables, sums/factrs of state variables and parameters, or other powers that have previously been specified. This HIV mode provides an example of the usage of power laws. 8.1.3.1 Phenomenological heterogeneity Without heterogeneity the force of infection might look like this. \\[ \\text{rate(S to E)} = \\beta \\left(\\frac{1}{N}\\right)I \\] Adding heterogeneity we might do this. \\[ \\text{rate(S to E)} = \\beta \\left(\\frac{1}{N}\\right)^{1+\\zeta}S^\\zeta I \\] When \\(\\zeta = 0\\) we recover the model without heterogeneity. We can then multiply this rate by \\(S\\) to get the flow. \\[ \\text{flow(S to E)} = S \\beta \\left(\\frac{1}{N}\\right)^{1+\\zeta}S^\\zeta I = \\beta \\left(\\frac{S}{N}\\right)^{1+\\zeta} I \\] 8.2 Additional Variables in the Simulation History The simulation_history function returns a data frame containing many of the variables in the model, with each row giving each time step in the simulation. This simulation_history function is introduced in the chapter on Simulation. This simulation history table is used for two purposes: (1) to return to the user as simulation output and (2) to compare with observed time series in in the process of Calibration. The simulation history contains the following variables in the following order: State variables Flow rates that vary in simulation time (constant rates are omitted) Sums of state variables and parameters factrs Expressions following the rules in [Flows Between States] of any of the variables in 1-4 above Lagged differenced versions of 1-5 Convolutions of 1-5 Items 5-7 consitute the additional variables in the simulation history. In the next sections we illustrate how to add such variables to the SIR model. 8.2.1 Simulation History Expressions TODO: describe add_sim_report_expr function 8.2.2 Lagged Differencing TODO: describe add_lag_diff function 8.2.3 Convolutions TODO: describe add_conv function "],["ensemble-forecasts.html", "9 Ensemble Forecasts 9.1 Time-Varying Ensemble Forecasts", " 9 Ensemble Forecasts Good forecasts include measures of uncertainty associated with each forecasted data point. The simulate_ensemble function allows one to make such forecasts. In Calibrating with Observation Error we fitted a model to simulated data with observation error. Here we use this model to illustrate the use of the simulate_ensemble function. The first thing to do before making a forecast is to extend the end date, so that we are actually forecasting the future. sir_obs_err_to_forecast = extend_end_date( sir_obs_err_calibrated, days_to_extend = 100 ) Next just pass the model that is ready for forecasting to the simulate_ensemble function. obs_err_forecasts = (simulate_ensemble( sir_obs_err_to_forecast, use_progress_bar = FALSE ) %&gt;% filter(var != &quot;S_to_I&quot;) ) The forecasts can be joined back to the observed data to make plots (TODO: fix the naming of the columns of these functions to be more consistent). obs_err_fits = (obs_err_forecasts %&gt;% left_join( noisy_data, c(&quot;Date&quot; = &quot;date&quot;, &quot;var&quot; = &quot;var&quot;), suffix = c(&quot;_fitted&quot;, &quot;&quot;) ) %&gt;% mutate( var = factor( var, levels = topological_sort(sir_obs_err_to_forecast)) ) ) (ggplot(obs_err_fits) + facet_wrap(~var, scales = &#39;free&#39;, nrow = 2) + geom_ribbon(aes(x = Date, ymax = upr, ymin = lwr), alpha = 0.5) + geom_point(aes(Date, value), alpha = 0.7) + geom_line(aes(Date, value_fitted), colour = &quot;red&quot;) ) ## Warning: Removed 833 rows containing missing values (`geom_point()`). 9.1 Time-Varying Ensemble Forecasts Forecasting often involves exploring what-if-scenarios. For example, what if the transmission rate jumped to high levels in the forecast period due to a policy option under consideration? Such scenario exploration can be done in McMasterPandemic by adding piece-wise time-variation of parameters in the forecasting period using the add_piece_wise function. sir_tv_to_forcast = (sir_cal_tv %&gt;% extend_end_date(days_to_extend = 120) %&gt;% add_piece_wise( data.frame( Date = &quot;2021-01-01&quot;, Symbol = &quot;beta&quot;, Value = 0.5, Type = &quot;abs&quot; ) ) ) An ensemble forecast can be produced with this scenario model. Here we do just that, while joining back the observed data so that we may plot both the fit and the forecast. (sir_tv_to_forcast %&gt;% simulate_ensemble(use_progress_bar = FALSE) %&gt;% filter(var != &quot;S_to_I&quot;) %&gt;% left_join( sir_cal_tv$observed$data, c(&quot;Date&quot; = &quot;date&quot;, &quot;var&quot; = &quot;var&quot;), suffix = c(&quot;_fitted&quot;, &quot;&quot;) ) %&gt;% mutate(var = factor(var, topological_sort(sir_cal_tv))) %&gt;% ggplot + facet_wrap(~var, ncol = 2) + geom_line(aes(Date, value)) + geom_line(aes(Date, value_fitted), colour = &#39;red&#39;) + geom_ribbon(aes(x = Date, ymax = upr, ymin = lwr), alpha = 0.5) ) ## Warning: Removed 121 rows containing missing values (`geom_line()`). Notice the mini-peak in infected individuals caused by the jump in transmission rate in the forecast period, accompanied by rapid susceptible depletion. "],["vectors.html", "10 Vectors", " 10 Vectors Throughout most of our discussions we have used a simple SIR model as an example. However, many real-world applications involve some kind of compartment structure. For example, the McMaster COVID modelling team used a model with vaccination structure where each epidemiological status (e.g. S, E, I, R) requires five compartments. Each of these five compartments represents a different vaccination status: unvaccinated, received first dose, protected by first dose, receieved second dose, protected by second dose. There are many other examples of model structure that multiply the numbers of compartments including age, variants, and space. As base epidemiological compartments are multiplied with structure, the scalar valued parameters, states, and rates become vectors and matrices. (TODO: describe matrix-formulations of the force of infection under structure). McMasterPandemic provides struc objects for doing symbolic matrix algebra that allows one to specify vector-valued rates to multiple flows at the same time (e.g. force of infection for every vaccination status). The scal, vec, and mat functions can be used to construct scalar-valued, vector-valued, and matrix-valued struc objects. A very simple example of struc objects is given by this Two-Strain SIR model. "],["hazard-smoothing.html", "11 Hazard Smoothing", " 11 Hazard Smoothing The Euler-multinomial distribution is a good place to get a little background on the hazard smoothing approach. \\[ p_j = \\left(1-\\exp\\left(-\\sum_i{r_i dt}\\right)\\right) \\frac{r_j}{\\sum_i r_i}. \\] The first piece is the probability of leaving the box at an exponential rate, and the second piece is that fraction of flows going to a particular box. Define the sums of the rows of the rate matrix. \\[ r_i = \\sum_{j=1}^n M_{ij} \\] Define the elements of a vector of exponentiated row sums \\[ \\rho_i = \\exp(-r_i) \\] Define the elements of a normalized state vector. \\[ \\tilde{s}_i = \\begin{cases} 0 &amp; r_i = 0 \\\\ \\frac{s_i}{r_i} &amp; \\text{otherwise} \\end{cases} \\] With these definitions we can define the modified flow matrix. \\[ F_{ij} = \\begin{cases} M_{ij}\\tilde{s}_i(1-\\rho_i) &amp; i \\ne j \\\\ 0 &amp; \\text{otherwise} \\end{cases} \\] This modified flow matrix can now be used in the same way as the unmodified flow matrix to produce state variable updates following spec version 0.0.2. "],["state-initialization.html", "12 State Initialization", " 12 State Initialization "],["outflows.html", "13 Outflows 13.1 Accumulators", " 13 Outflows In compartmental modelling we typically want to balance each flow out of a boxes with an equal flow into another box. This is because individuals are simply changing their epidemiological status as they move between boxes, and the total number of individuals across the boxes remains constant. McMasterPandemic assumes this standard balance between inflows and outflows by default. This default makes it very easy to enforce inflow-outflow balance. This ease of use contrasts with the standard practice of writing down difference or differential equations to define the model (e.g. POMP, STAN). This equation-style interface requires that the user make sure each inflow term in one equation is appropriately balanced by an outflow term in another equation. In McMasterPandemic you define the inflows, and by default it automatically creates balancing outflows. 13.1 Accumulators It is sometimes necessary to override this default inflow-outflow balance. One use-case that requires something other than the default is in the definition of an accumulator compartment, which allows one to track the cumulative number of individuals that have ever entered a particular compartment or set of compartments. For example, suppose that we want to keep track of the total number of individuals who have ever been infected in our SIR model. To do this we define an X accumulator compartment. This X box has the same inflow from S as does I, but we restrict outflow from S as individuals flow in to X – otherwise we would double-count the draining of S. We specify this custom outflow model with the add_outflow function. sir_with_accumulator = (flexmodel( params = c(beta = 0.1, gamma = 0.01, N = 100), state = c(S = 99, I = 1, R = 0, X = 1), start_date = &quot;2020-03-11&quot;, end_date = &quot;2020-12-01&quot; ) %&gt;% add_rate(&quot;S&quot;, &quot;I&quot;, ~ (I) * (beta) * (1/N)) %&gt;% add_rate(&quot;S&quot;, &quot;X&quot;, ~ (I) * (beta) * (1/N)) %&gt;% add_rate(&quot;I&quot;, &quot;R&quot;, ~ (gamma)) %&gt;% add_outflow(from = &quot;S|I&quot;, to = &quot;I|R&quot;) ) The add_outflow function here takes two regular expressions, from and to. The first from regular expression matches states that individuals must flow out of, only if the flow is to states matched by the second to regular expression. (sir_with_accumulator %&gt;% simulation_history %&gt;% select(-S_to_I, -S_to_X) %&gt;% pivot_longer(-Date, names_to = &quot;State&quot;, values_to = &quot;Population&quot;) %&gt;% ggplot() + geom_line(aes(Date, Population, colour = State)) ) Note how sometime in July almost everyone has been infected at some point in the epidemic. "],["tmb-engine.html", "14 TMB Engine", " 14 TMB Engine The initial engine for calibrating and forecasting in McMasterPandemic was R itself. In the refactored version of McMasterPandemic we use template model builder, or TMB. It is possible to interact with TMB objects directly using the McMasterPandemic::tmb_fun function, which we illustrate in this section to do MCMC simulation. HACK: For some reason tmbstan is not working unless we compile the C++ code rather than use the package-compiled objects. cpp_dir = system.file(&#39;tmb&#39;, options()$MP_flex_spec_version, package = &quot;McMasterPandemic&quot;) set_spec_version(options()$MP_flex_spec_version, cpp_dir, use_version_directories = FALSE) ## [1] &quot;0.2.1&quot; We can get the TMB object by calling the tmb_fun function on a flexmodel_to_calibrate object. sir_obs_err_tmb = tmb_fun(sir_obs_err_to_calibrate) We can pass this tmb_fun object to tmbstan (in the tmbstan package) to generate MCMC samples using rstan. sir_obs_err_stan = tmbstan( sir_obs_err_tmb, chains = 1 ) ## ## SAMPLING FOR MODEL &#39;tmb_generic&#39; NOW (CHAIN 1). ## Chain 1: ## Chain 1: Gradient evaluation took 0.000354 seconds ## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 3.54 seconds. ## Chain 1: Adjust your expectations accordingly! ## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1: ## Chain 1: Elapsed Time: 2.2725 seconds (Warm-up) ## Chain 1: 1.54074 seconds (Sampling) ## Chain 1: 3.81324 seconds (Total) ## Chain 1: names(sir_obs_err_stan) = c( names(tmb_params_trans(sir_obs_err_to_calibrate)), &quot;log_posterior&quot; ) traceplot(sir_obs_err_stan, ncol = 1) sir_obs_err_stan ## Inference for Stan model: macpan. ## 1 chains, each with iter=2000; warmup=1000; thin=1; ## post-warmup draws per chain=1000, total post-warmup draws=1000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% ## log_beta -2.30 0.00 0.01 -2.32 -2.31 -2.30 -2.29 -2.28 ## log_nb_disp_I 9.99 0.04 1.05 7.95 9.29 9.99 10.72 12.00 ## log_posterior -802.65 0.05 1.07 -805.32 -803.08 -802.34 -801.91 -801.66 ## n_eff Rhat ## log_beta 758 1 ## log_nb_disp_I 740 1 ## log_posterior 531 1 ## ## Samples were drawn using NUTS(diag_e) at Mon Jan 30 16:27:52 2023. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split chains (at ## convergence, Rhat=1). One may also use shinystan with these objects. "],["examples.html", "15 Examples 15.1 Hello World: Simulating an SIR Model 15.2 SI 15.3 SEIR 15.4 Structure: Two-Strain SIR 15.5 Erlang SEIR 15.6 SIRV 15.7 Variolation model 15.8 SEIRD 15.9 Covid SEIR 15.10 BC Covid Omicron 15.11 Classic McMasterPandemic 15.12 Granich HIV Model", " 15 Examples 15.1 Hello World: Simulating an SIR Model state = c(S = 20000, I = 100, R = 0) sir_model = ( flexmodel( params = c( gamma = 0.06, beta = 0.15, N = sum(state) ), state = state, start_date = &quot;2000-01-01&quot;, end_date = &quot;2000-05-01&quot;, do_hazard = FALSE ) %&gt;% add_rate(&quot;S&quot;, &quot;I&quot;, ~ (1/N) * (beta) * (I)) %&gt;% add_rate(&quot;I&quot;, &quot;R&quot;, ~ (gamma)) ) sir_model ## from to n_fctrs n_prdcts n_vrbls state_dependent time_varying ## S_to_I S I 3 1 3 TRUE FALSE ## I_to_R I R 1 1 1 FALSE FALSE ## sum_dependent ## S_to_I FALSE ## I_to_R FALSE (sir_model %&gt;% simulation_history %&gt;% select(-S_to_I) %&gt;% pivot_longer(!Date) %&gt;% rename(state = value, epi_cat = name) %&gt;% mutate(epi_cat = factor(epi_cat, levels = topological_sort(sir_model))) %&gt;% ggplot + geom_line(aes(x = Date, y = state, colour = epi_cat)) ) (sir_model %&gt;% simulation_history %&gt;% rename(`force of infection` = S_to_I) %&gt;% ggplot + geom_line(aes(x = Date, y = `force of infection`)) ) One may use this functionality to compute basic epidemiological parameters such as \\(R_0\\), \\(r\\), and \\(\\bar{G}\\). We do this by modifying the model slightly, simulating, and summarizing the output. TODO: actually compute these parameters. epi_pars(sir_model , exposed_state_nm = &quot;I&quot; , foi_nm = &quot;S_to_I&quot; , N = 1 ) 15.2 SI si = (flexmodel( params = c(beta = 0.15, gamma = 0.06, N = 100), state = c(S = 99, I = 1), start_date = &quot;2000-01-01&quot;, end_date = &quot;2000-06-01&quot; ) %&gt;% add_rate(&quot;S&quot;, &quot;I&quot;, ~ (I) * (beta) * (1/N)) %&gt;% add_rate(&quot;I&quot;, &quot;S&quot;, ~ (gamma)) %&gt;% add_factr(&quot;ratio&quot;, ~ (gamma) * (1/beta)) %&gt;% add_factr(&quot;S_hat&quot;, ~ (N) * (ratio)) %&gt;% add_factr(&quot;I_hat&quot;, ~ (N) * (1 - ratio)) ) (si %&gt;% simulation_history %&gt;% select(-S_to_I, -ratio) %&gt;% pivot_longer(-Date, names_to = &quot;State&quot;, values_to = &quot;Population&quot;) %&gt;% separate(State, c(&quot;State&quot;, &quot;Equilibrium&quot;), &quot;_&quot;) %&gt;% mutate(Equilibrium = ifelse(is.na(Equilibrium), &#39;no&#39;, &#39;yes&#39;)) %&gt;% ggplot + geom_line(aes(Date, Population, colour = State, linetype = Equilibrium)) ) ## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 306 rows [1, 2, 5, 6, 9, ## 10, 13, 14, 17, 18, 21, 22, 25, 26, 29, 30, 33, 34, 37, 38, ...]. 15.3 SEIR state = c(S = 20000, E = 0, I = 100, R = 0) seir_model = ( flexmodel( params = c( alpha = 0.05, gamma = 0.06, beta = 0.15, N = sum(state) ), state = state, start_date = &quot;2000-01-01&quot;, end_date = &quot;2000-05-01&quot;, do_hazard = TRUE, ) %&gt;% add_rate(&quot;S&quot;, &quot;E&quot;, ~ (1/N) * (beta) * (I)) %&gt;% add_rate(&quot;E&quot;, &quot;I&quot;, ~ (alpha)) %&gt;% add_rate(&quot;I&quot;, &quot;R&quot;, ~ (gamma)) ) seir_model ## from to n_fctrs n_prdcts n_vrbls state_dependent time_varying ## S_to_E S E 3 1 3 TRUE FALSE ## E_to_I E I 1 1 1 FALSE FALSE ## I_to_R I R 1 1 1 FALSE FALSE ## sum_dependent ## S_to_E FALSE ## E_to_I FALSE ## I_to_R FALSE 15.4 Structure: Two-Strain SIR strains = c(&quot;wild&quot;, &quot;variant&quot;) state = c( S = 20000, I_wild = 49, I_variant = 1, R_wild = 0, R_variant = 0 ) two_strain_model = ( flexmodel( params = c( gamma = 0.06, beta_wild = 0.15, beta_variant = 0.25, N = sum(state) ), state = state, start_date = &quot;2000-01-01&quot;, end_date = &quot;2000-05-01&quot;, do_hazard = TRUE ) %&gt;% vec_rate( &quot;S&quot;, &quot;I&quot; %_% strains, vec(&quot;beta&quot; %_% strains) * struc(&quot;1/N&quot;) * vec(&quot;I&quot; %_% strains) ) %&gt;% rep_rate(&quot;I&quot;, &quot;R&quot;, ~ (gamma)) ) regex = &quot;^(S|I|R)(_*)(|wild|variant)$&quot; (two_strain_model %&gt;% simulation_history %&gt;% select(Date, matches(regex)) %&gt;% pivot_longer(!Date) %&gt;% rename(state = value) %&gt;% mutate(strain = sub(pattern = regex, replacement = &quot;\\\\3&quot;, name)) %&gt;% mutate(epi_cat = sub(pattern = regex, replacement = &quot;\\\\1&quot;, name)) %&gt;% mutate(strain = factor(strain, c(&quot;&quot;, &quot;wild&quot;, &quot;variant&quot;))) %&gt;% mutate(epi_cat = factor(epi_cat, c(&quot;S&quot;, &quot;I&quot;, &quot;R&quot;))) %&gt;% ggplot + geom_line(aes(x = Date, y = state, colour = epi_cat, linetype = strain)) ) (two_strain_model %&gt;% simulation_history %&gt;% pivot_longer(starts_with(&quot;S_to_I&quot;)) %&gt;% mutate(name = sub(&quot;S_to_I_&quot;, &quot;&quot;, name)) %&gt;% rename(`force of infection` = value) %&gt;% rename(strain = name) %&gt;% ggplot + geom_line(aes(x = Date, y = `force of infection`, colour = strain)) ) 15.5 Erlang SEIR David, Jonathan, and David describe the Erlang SEIR model in continuous time. Here is a discrete time version of it. n = 4 # number of I states m = 6 # number of E states erlang_seir = (flexmodel( # FIXME: only working for no demography (so mu = 0 for now) params = c(mu = 0, beta = 1.5, m = m, n = n, gamma = 1.2, sigma = 0.1), state = c( S = 1-1e-3, layered_zero_state(&quot;E&quot; %_% 1:m), I_1 = 1e-3, layered_zero_state(&quot;I&quot; %_% 2:n), R = 0, D = 0, . = 1), start_date = &quot;2000-01-01&quot;, end_date = &quot;2000-04-01&quot;, do_hazard = TRUE ) %&gt;% add_state_param_sum(&quot;I&quot;, &quot;^I_[0-9]+&quot;) # birth %&gt;% add_rate(&quot;.&quot;, &quot;S&quot;, ~ (mu)) # death %&gt;% rep_rate( from = c(&quot;S&quot;, &quot;E&quot; %_% 1:m, &quot;I&quot; %_% 1:n, &quot;R&quot;), to = &quot;D&quot;, formula = ~ (mu)) # infection %&gt;% add_rate(&quot;S&quot;, &quot;E_1&quot;, ~ (beta) * (I)) # become infectious %&gt;% add_rate(&quot;E&quot; %_% m, &quot;I_1&quot;, ~ (m) * (sigma)) # sojourn through exposed compartments %&gt;% rep_rate( &quot;E&quot; %_% 1:(m-1), &quot;E&quot; %_% 2:m, ~ (m) * (sigma) ) # sojourn through infectious compartments %&gt;% rep_rate( &quot;I&quot; %_% 1:(n-1), &quot;I&quot; %_% 2:n, ~ (n) * (gamma) ) # recovery %&gt;% add_rate(&quot;I&quot; %_% n, &quot;R&quot;, ~ (n) * (gamma)) # nothing flows out of . because it is a dummy # state used to generate flows that are not per-capita %&gt;% add_outflow(&quot;[^.]&quot;) ) (erlang_seir %&gt;% simulation_history %&gt;% select(-., -D, -S_to_E_1) %&gt;% pivot_longer(-Date, names_to = &quot;State&quot;, values_to = &quot;Count&quot;) %&gt;% mutate(State = sub(&quot;_[0-9]+&quot;, &quot;&quot;, State)) %&gt;% group_by(Date, State) %&gt;% summarise(Count = sum(Count)) %&gt;% ungroup %&gt;% mutate(State = factor(State, c(&quot;S&quot;, &quot;E&quot;, &quot;I&quot;, &quot;R&quot;))) %&gt;% ggplot() + geom_line(aes(Date, Count, colour = State)) ) ## `summarise()` has grouped output by &#39;Date&#39;. You can override using the ## `.groups` argument. # check to make sure that the population density # remains constant at one (erlang_seir %&gt;% simulation_history %&gt;% select(-Date, -., -D, -S_to_E_1, -I) %&gt;% rowSums %&gt;% sapply(all.equal, 1L) %&gt;% sapply(isTRUE) %&gt;% all ) ## [1] TRUE 15.6 SIRV state = c(S = 20000, I = 100, R = 0, V = 0) params = c( gamma = 0.06, beta = 0.15, v = 0, # initial vaccination rate N = sum(state) ) # roll out the vaccine by bumping the # vaccination rate twice params_timevar = data.frame( Date = c(&quot;2020-02-01&quot;, &quot;2020-03-01&quot;), Symbol = c(&quot;v&quot;, &quot;v&quot;), Value = c(0.01, 0.1), Type = c(&quot;abs&quot;, &quot;abs&quot;)) sirv_model = ( flexmodel( params = params, state = state, params_timevar = params_timevar, start_date = &quot;2020-01-01&quot;, end_date = &quot;2020-05-01&quot;, do_hazard = TRUE ) %&gt;% add_rate(&quot;S&quot;, &quot;I&quot;, ~ (beta) * (1/N) * (I)) %&gt;% add_rate(&quot;I&quot;, &quot;R&quot;, ~ (gamma)) %&gt;% add_rate(&quot;S&quot;, &quot;V&quot;, ~ (v)) ) (sirv_model %&gt;% simulation_history %&gt;% select(Date, matches(&quot;^(S|I|R|V)$&quot;)) %&gt;% pivot_longer(!Date) %&gt;% rename(state = value, epi_cat = name) %&gt;% mutate(epi_cat = factor(epi_cat, topological_sort(sirv_model))) %&gt;% ggplot + geom_line(aes(x = Date, y = state, colour = epi_cat)) + geom_vline(aes(xintercept = as.Date(Date)), data = params_timevar, colour = &#39;lightgrey&#39;) ) 15.7 Variolation model The variolation model is … TODO: add description. state = c( S = 20000, I_severe = 50, I_mild = 50, R_mild = 0, R_severe = 0 ) params = c( nu = 0.0105, # birth rate mu = 0.0105, # death rate delta = 1/7, # waning immunity rate gamma_mild = 1/(3.3 + 9), # recovery rate of mild cases gamma_severe = 1/(3.3 + 14), # recovery rate of severe cases beta_mild = 0.15, # transmission rate of infections leading to mild cases beta_severe = 0.3, # transmission rate of infections leading to severe cases m = 0.6 # probability of developing mild illness ) # model structure all_states = names(state) severity = c(&quot;mild&quot;, &quot;severe&quot;) beta_vec = vec(&quot;beta&quot; %_% severity) I_vec = vec(&quot;I&quot; %_% severity) foi = kronecker(vec(&quot;m&quot;, &quot;1-m&quot;), sum(beta_vec * I_vec * struc(&quot;1/N&quot;))) variolation_model &lt;- ( flexmodel( params = params, state = state, start_date = &quot;2020-01-01&quot;, end_date = &quot;2020-04-01&quot; ) %&gt;% add_state_param_sum(&quot;N&quot;, any_var(state)) # births and deaths # (FIXME: this only works if nu = mu) %&gt;% rep_rate( all_states, &quot;S&quot;, ~ (nu) ) # infection %&gt;% vec_rate( &quot;S&quot;, &quot;I&quot; %_% severity, foi ) # waning immunity %&gt;% rep_rate( &quot;R&quot; %_% severity, &quot;S&quot;, ~ (delta) ) # recovery %&gt;% vec_rate( &quot;I&quot; %_% severity, &quot;R&quot; %_% severity, vec(&quot;gamma&quot; %_% severity) ) ) (variolation_model %&gt;% simulation_history %&gt;% select(Date, matches(any_var(variolation_model$state))) %&gt;% pivot_longer(!Date) %&gt;% rename(state = value, epi_cat = name) %&gt;% ggplot + geom_line(aes(x = Date, y = state, colour = epi_cat)) ) 15.8 SEIRD This is the Mac Theo Bio Model. state = c(S = 20000, E = 50, I = 50, R = 0, D = 0, Null = 0) params = c( # transmission rates of susceptibles from live and dead individuals beta_I = 5, beta_D = 2, # average times in various boxes T_E = 10, T_I = 14, T_D = 10, # probability of death given infection f = 0.5 ) seird_model = ( flexmodel( params = params, state = state, start_date = &quot;2000-01-01&quot;, end_date = &quot;2000-03-01&quot;, do_hazard = TRUE ) %&gt;% add_state_param_sum(&quot;N&quot;, any_var(state)) %&gt;% add_rate(&quot;S&quot;, &quot;E&quot;, ~ (beta_I) * (1/N) * (I) + (beta_D) * (1/N) * (D)) %&gt;% add_rate(&quot;E&quot;, &quot;I&quot;, ~ (1/T_E)) %&gt;% add_rate(&quot;I&quot;, &quot;R&quot;, ~ (1/T_I) * (1 - f)) %&gt;% add_rate(&quot;I&quot;, &quot;D&quot;, ~ (1/T_I) * (f)) %&gt;% add_rate(&quot;D&quot;, &quot;Null&quot;, ~ (1/T_D)) ) (seird_model %&gt;% simulation_history %&gt;% select(Date, matches(any_var(state))) %&gt;% pivot_longer(!Date) %&gt;% rename(state = value, epi_cat = name) %&gt;% mutate(epi_cat = factor(epi_cat, levels = topological_sort(seird_model))) %&gt;% ggplot + geom_line(aes(x = Date, y = state, colour = epi_cat)) ) 15.9 Covid SEIR The BC covid modelling group uses this compartmental model for their inference and forecasting work. This model can be expressed in McMasterPandemic with the following. foi = ( vec(c(&quot;1&quot;, &quot;f&quot;)) * struc(&quot;beta&quot;) * struc(&quot;1/N&quot;) * (struc(&quot;(I) + (E2)&quot;) + (struc(&quot;f&quot;) * struc(&quot;(Id) + (E2d)&quot;))) ) params = c( N = 5100000, D = 5, k1 = 0.2, k2 = 1, q = 0.05, ud = 0.1, ur = 0.02, psir = 0.3, shape = 1.73, scale = 9.85, beta = 0.433, f = 1 ) state = c( S = 849999, E1 = 0.53, E2 = 0.13, I = 0.67, Q = 0, R = 0, Sd = 4249993, E1d = 2.67, E2d = 0.67, Id = 3.33, Qd = 0, Rd = 0 ) base_states = names(state)[1:6] dist_states = base_states %+% &quot;d&quot; strats = c(&quot;&quot;, &quot;d&quot;) # distancing strategies ramp_period = seq(from = ymd(20210315), to = ymd(20210322), by = 1) time_ratio = rev((seq_along(ramp_period) - 1) / (length(ramp_period) - 1)) f2 = 0.22 params_timevar = data.frame( Date = ramp_period, Symbol = rep(&quot;f&quot;, length(ramp_period)), Value = f2 + time_ratio * (1 - f2), Type = rep(&quot;abs&quot;, length(ramp_period)) ) model = ( flexmodel( params = params, state = state, start_date = &quot;2021-02-01&quot;, end_date = &quot;2021-06-01&quot;, do_hazard = TRUE, params_timevar = params_timevar ) # flow between distancing strategies %&gt;% rep_rate(base_states, dist_states, ~ (ud)) %&gt;% rep_rate(dist_states, base_states, ~ (ur)) # force of infection %&gt;% vec_rate( &quot;S&quot; %+% strats, &quot;E1&quot; %+% strats, foi ) # flow within distancing strategies %&gt;% rep_rate( &quot;E1&quot; %+% strats, &quot;E2&quot; %+% strats, ~ (k1) ) %&gt;% rep_rate( &quot;E2&quot; %+% strats, &quot;I&quot; %+% strats, ~ (k2) ) %&gt;% rep_rate( &quot;I&quot; %+% strats, &quot;Q&quot; %+% strats, ~ (q) ) %&gt;% rep_rate( expand_names(c(&quot;I&quot;, &quot;Q&quot;), strats, &quot;&quot;), expand_names(c(&quot;R&quot;, &quot;R&quot;), strats, &quot;&quot;), ~ (1/D) ) ) (model %&gt;% simulation_history %&gt;% select(Date, matches(any_var(model$state))) %&gt;% pivot_longer(!Date) %&gt;% ggplot() + facet_wrap(~ name, scales = &#39;free&#39;, ncol = 2) + geom_line(aes(Date, value)) ) 15.10 BC Covid Omicron The BC group also developed a model with two strains for the Omicron wave of Covid-19. DISCLAIMER: This is not meant to illustrate a realistic forecast, but rather to illustrate how the basic model structure can be expressed in McMasterPandemic params = c( sigma=1/3, # incubation period (3 days) (to fixed) gamma=1/(5), #recovery rate (fixed) nu =0.007, #vax rate: 0.7% per day (fixed) mu=1/(82*365), # 1/life expectancy (fixed) w1 = 1/(3*365),# waning rate from R to S (fixed) w2 = 1/(3*365), # waning rate from Rv to V (fixed) w3 = 1/(3*365),# waning rate Rw to W (fixed) ve=1, # I think this should be 1. it is not really efficacy ( fixed) beta_r=0.72, #transmission rate (to estimate) (0.35) beta_m=0.8*2.2, #transmission rate (to estimate)(*1.9) epsilon_r = (1-0.8), # % this should be 1-ve epsilon_m = (1-0.6), # % escape capacity #(fixed) b= 0.006, # booster rate (fixed) beff = 0.7, # booster efficacy wf=0.2, # protection for newly recoverd #0.2 N=5e6, E0=5, S0=1-1e-5, c=1 ) # dimensions of model structure vax_states = c(&quot;unvax&quot;, &quot;onedose&quot;, &quot;boost&quot;) variant_states = c(&quot;delta&quot;, &quot;omicron&quot;) epi_states = c(&quot;S&quot;, &quot;E&quot; %_% variant_states, &quot;I&quot; %_% variant_states, &quot;R&quot;) # vectors representing variant model structure I_delta = vec(&quot;I&quot; %_% &quot;delta&quot; %_% vax_states) I_omicron = vec(&quot;I&quot; %_% &quot;omicron&quot; %_% vax_states) E_delta = vec(&quot;E&quot; %_% &quot;delta&quot; %_% vax_states) E_omicron = vec(&quot;E&quot; %_% &quot;omicron&quot; %_% vax_states) # initial state vector state = layered_zero_state(epi_states, vax_states) all_states = names(state) state[] = unname(make_init(params)) print(state) ## S_unvax E_delta_unvax E_omicron_unvax I_delta_unvax ## 9.106607e+05 6.480000e+02 1.748571e+01 1.110857e+03 ## I_omicron_unvax R_unvax S_onedose E_delta_onedose ## 2.997551e+01 1.014000e+05 3.502789e+06 5.924571e+02 ## E_omicron_onedose I_delta_onedose I_omicron_onedose R_onedose ## 1.974857e+01 1.015641e+03 3.385469e+01 3.893760e+05 ## S_boost E_delta_boost E_omicron_boost I_delta_boost ## 1.460132e+05 2.468571e+01 8.228571e-01 4.231837e+01 ## I_omicron_boost R_boost ## 1.410612e+00 1.622400e+04 two_strain_bc = (flexmodel( params = params, state = state, start_date = &quot;2022-01-01&quot;, end_date = &quot;2022-05-01&quot;, do_hazard = TRUE ) # sum over every vax status to get # total numbers in I boxes for each # variant %&gt;% add_state_param_sum(&quot;I_delta&quot;, &quot;I_delta_&quot;) %&gt;% add_state_param_sum(&quot;I_omicron&quot;, &quot;I_omicron_&quot;) # R to S boxes for every vax status # -- waning %&gt;% vec_rate( from = &quot;R&quot; %_% vax_states, to = &quot;S&quot; %_% vax_states, vec(&#39;w1&#39;, &#39;w2&#39;, &#39;w3&#39;) ) # S_delta to E_delta for every vax status # -- delta force of infection %&gt;% vec_rate( from = &quot;S&quot; %_% vax_states, to = &quot;E&quot; %_% &quot;delta&quot; %_% vax_states, struc(&quot;(c) * (beta_r) * (1/N) * (I_delta)&quot;) * vec(&quot;1&quot;, &quot;epsilon_r&quot;, &quot;epsilon_r&quot;) ) # S_omicron to E_omicron for every vax status # -- omicron force of infection %&gt;% vec_rate( from = &quot;S&quot; %_% vax_states, to = &quot;E&quot; %_% &quot;omicron&quot; %_% vax_states, struc(&quot;(c) * (beta_m) * (1/N) * (I_omicron)&quot;) * vec(&quot;1&quot;, &quot;epsilon_m&quot;, &quot;epsilon_m&quot;) ) # R to E_delta for every vax status # -- delta force of infection of recovered individuals %&gt;% rep_rate( from = &quot;R&quot; %_% vax_states, to = &quot;E&quot; %_% &quot;delta&quot; %_% vax_states, ~ (wf) * (epsilon_r) * (c) * (beta_r) * (1/N) * (I_delta) ) # R to E_omicron for every vax status # -- omicron force of infection of recovered individuals %&gt;% rep_rate( from = &quot;R&quot; %_% vax_states, to = &quot;E&quot; %_% &quot;omicron&quot; %_% vax_states, ~ (wf) * (epsilon_m) * (c) * (beta_m) * (1/N) * (I_omicron) ) # E to I for all variant-vax combinations %&gt;% rep_rate( from = &quot;E&quot; %_% expand_names(variant_states, vax_states), to = &quot;I&quot; %_% expand_names(variant_states, vax_states), ~ (sigma) ) # recovery for all variant-vax combinations %&gt;% rep_rate( from = &quot;I&quot; %_% expand_names(variant_states, vax_states), to = &quot;R&quot; %_% rep(vax_states, each = length(variant_states)), ~ (gamma) ) # demographics %&gt;% rep_rate( from = all_states, to = &quot;S_unvax&quot;, ~ (mu) ) # vaccination %&gt;% add_rate(from = &quot;S_unvax&quot;, to = &quot;S_onedose&quot;, ~ (nu) * (ve)) %&gt;% add_rate(from = &quot;S_onedose&quot;, to = &quot;S_boost&quot;, ~ (b) * (ve)) ) category_pattern = &quot;^(S|E|I|R)(_omicron|_delta)?_(unvax|onedose|boost)$&quot; (two_strain_bc %&gt;% simulation_history %&gt;% select(Date, matches(category_pattern)) %&gt;% pivot_longer(-Date, names_to = &quot;Compartment&quot;, values_to = &quot;State&quot;) %&gt;% mutate(`Epi Status` = sub(category_pattern, &#39;\\\\1\\\\2&#39;, Compartment, perl = TRUE)) %&gt;% mutate(`Vaccination Status` = sub(category_pattern, &#39;\\\\3&#39;, Compartment, perl = TRUE)) %&gt;% arrange(`Epi Status`, `Vaccination Status`) %&gt;% mutate(Compartment = factor(Compartment, all_states)) %&gt;% ggplot() + facet_wrap( ~ Compartment, ncol = 3, scales = &#39;free&#39;, dir = &#39;v&#39;) + geom_line(aes(Date, State)) ) 15.11 Classic McMasterPandemic params = read_params(&quot;ICU1.csv&quot;) model = (flexmodel( params = params, state = make_state(params = params), start_date = &quot;2020-03-10&quot;, end_date = &quot;2020-12-10&quot;, do_make_state = FALSE, do_hazard = TRUE ) %&gt;% add_rate(&quot;E&quot;, &quot;Ia&quot;, ~ (alpha) * (sigma)) %&gt;% add_rate(&quot;E&quot;, &quot;Ip&quot;, ~ (1 - alpha) * (sigma)) %&gt;% add_rate(&quot;Ia&quot;, &quot;R&quot;, ~ (gamma_a)) %&gt;% add_rate(&quot;Ip&quot;, &quot;Im&quot;, ~ (mu) * (gamma_p)) %&gt;% add_rate(&quot;Ip&quot;, &quot;Is&quot;, ~ (1 - mu) * (gamma_p)) %&gt;% add_rate(&quot;Im&quot;, &quot;R&quot;, ~ (gamma_m)) %&gt;% add_rate(&quot;Is&quot;, &quot;H&quot;, ~ (1 - nonhosp_mort) * (phi1) * (gamma_s)) %&gt;% add_rate(&quot;Is&quot;, &quot;ICUs&quot;, ~ (1 - nonhosp_mort) * (1 - phi1) * (1 - phi2) * (gamma_s)) %&gt;% add_rate(&quot;Is&quot;, &quot;ICUd&quot;, ~ (1 - nonhosp_mort) * (1 - phi1) * (phi2) * (gamma_s)) %&gt;% add_rate(&quot;Is&quot;, &quot;D&quot;, ~ (nonhosp_mort) * (gamma_s)) %&gt;% add_rate(&quot;ICUs&quot;, &quot;H2&quot;, ~ (psi1)) %&gt;% add_rate(&quot;ICUd&quot;, &quot;D&quot;, ~ (psi2)) %&gt;% add_rate(&quot;H2&quot;, &quot;R&quot;, ~ (psi3)) %&gt;% add_rate(&quot;H&quot;, &quot;R&quot;, ~ (rho)) %&gt;% add_rate(&quot;Is&quot;, &quot;X&quot;, ~ (1 - nonhosp_mort) * (phi1) * (gamma_s)) %&gt;% add_rate(&quot;S&quot;, &quot;E&quot;, ~ (Ia) * (beta0) * (1 / N) * (Ca) + (Ip) * (beta0) * (1 / N) * (Cp) + (Im) * (beta0) * (1 / N) * (Cm) * (1 - iso_m) + (Is) * (beta0) * (1 / N) * (Cs) * (1 - iso_s)) %&gt;% add_outflow(&quot;.+&quot;, &quot;^(S|E|I|H|ICU|D|R)&quot;) ) (model %&gt;% simulation_history %&gt;% pivot_longer(!Date) %&gt;% mutate(name = factor(name, levels = topological_sort(model))) %&gt;% ggplot() + facet_wrap(~ name, scales = &#39;free&#39;, ncol = 3) + geom_line(aes(Date, value)) ) 15.12 Granich HIV Model The HIV model from Granich et al (2008). start_date = ymd(20220501) end_date = start_date + days(30) params = c( # phenomenological heterogeneity parameters and constants alpha = 0.1, lambda0 = 0.002, n = 1, # exponential decrease when n = 1 e = exp(1), minus_1 = -1, # background birth and mortality rates beta = 0.02, mu = 0.01, one = 1, # treatment efficacy (smaller is less infectious) epsilon = 0.2, # disease progression rate rho = 0.15, # treatment rate tau = 0.8, # value from paper # treatment stopping rate phi = 0.015, # value from paper # disease progression rate for treated individuals sigma = 0.1 ) number_of_stages = 4 state = c( S = 999, layered_zero_state(&quot;I&quot;, 1:number_of_stages), layered_zero_state(&quot;A&quot;, 1:number_of_stages), D_disease = 0, D_background = 0 #birth_pool = 1000 ) state[&quot;I_1&quot;] = 1 alive_state_nms = grep(&quot;^(S|I|A)&quot;, names(state), value = TRUE) Ivec = vec(&quot;I&quot; %_% 1:number_of_stages) Avec = vec(&quot;A&quot; %_% 1:number_of_stages) epsilon = struc(&quot;epsilon&quot;) I = as.character(sum(Ivec) + sum(Avec)) J = as.character(sum(Ivec) + sum(epsilon * Avec)) granich = (flexmodel( params = params, state = state, start_date = start_date, end_date = end_date, do_hazard = TRUE ) %&gt;% add_state_param_sum(&quot;N&quot;, &quot;^(S|I|A)&quot;) %&gt;% add_factr(&quot;I&quot;, I) %&gt;% add_factr(&quot;J&quot;, J) %&gt;% add_factr(&quot;minus_alpha&quot;, ~ (alpha) * (minus_1)) %&gt;% add_factr(&quot;P&quot;, ~ (I) * (1/N)) %&gt;% add_pow(&quot;het_exponent&quot;, &quot;P&quot;, &quot;n&quot;, &quot;minus_alpha&quot;) %&gt;% add_pow(&quot;lambda&quot;, &quot;e&quot;, &quot;het_exponent&quot;, &quot;lambda0&quot;) %&gt;% rep_rate( from = alive_state_nms, to = &quot;S&quot;, ~ (beta) ) %&gt;% rep_rate( from = alive_state_nms, to = &quot;D_background&quot;, ~ (mu) ) # transmission %&gt;% add_rate( from = &quot;S&quot;, to = &quot;I_1&quot;, ~ (lambda) * (S) * (J) * (1/N) ) # treatment dynamics %&gt;% rep_rate( from = &quot;I&quot; %_% (1:number_of_stages), to = &quot;A&quot; %_% (1:number_of_stages), ~ (tau) ) %&gt;% rep_rate( from = &quot;A&quot; %_% (1:number_of_stages), to = &quot;I&quot; %_% (1:number_of_stages), ~ (phi) ) # disease progression %&gt;% rep_rate( from = &quot;I&quot; %_% (1:(number_of_stages - 1)), to = &quot;I&quot; %_% (2:number_of_stages), ~ (rho) ) %&gt;% rep_rate( from = &quot;A&quot; %_% (1:(number_of_stages - 1)), to = &quot;A&quot; %_% (2:number_of_stages), ~ (sigma) ) # disease death %&gt;% add_rate(&quot;I&quot; %_% number_of_stages, &quot;D_disease&quot;, ~ (rho)) %&gt;% add_rate(&quot;A&quot; %_% number_of_stages, &quot;D_disease&quot;, ~ (sigma)) #%&gt;% add_outflow(from = &quot;^[A-Z]&quot;) # don&#39;t flow out of the &#39;birth pool&#39; %&gt;% add_outflow( from = &#39;.+&#39;, to = &#39;^(I|A|D)_&#39; ) %&gt;% add_sim_report_expr(&quot;Itotal&quot;, sum(Ivec)) %&gt;% add_sim_report_expr(&quot;Atotal&quot;, sum(Avec)) ) (granich %&gt;% simulation_history %&gt;% select(Date, S, Itotal, Atotal, J, D_background, D_disease, lambda, N, P) %&gt;% pivot_longer(-Date) %&gt;% ggplot + facet_wrap(~ name, ncol = 3, scales = &#39;free&#39;) + geom_line(aes(Date, value)) ) "],["troubleshooting.html", "16 Troubleshooting 16.1 NaN-Valued Objective Function 16.2 Non-Positive Definite Covariance Matrix", " 16 Troubleshooting 16.1 NaN-Valued Objective Function 16.1.1 Simulated time-series close to zero When the simulated values that are being compared with data are close to zero (e.g. less than 1e-12), the negative binomial loss function often returns NaN. This can be fixed by setting do_sim_constraint = TRUE as an argument to flexmodel or whatever model constructor is being used (e.g. make_vaccination_model). This flag causes the simulated values to pass through the following soft-thresholding function to keep the simulations, \\(x\\), from falling below a tolerance, \\(\\epsilon\\). \\[ x + \\frac{\\epsilon}{1-(x-\\epsilon)/\\epsilon + (x-\\epsilon)^2/\\epsilon^2} \\] This tolerance can be adjusted by setting the sim_lower_bound = 1e-12. Note that both do_sim_constraint and sim_lower_bound can be set using the global options MP_default_do_sim_constraint and MP_default_sim_lower_bound. 16.1.2 Negative rate matrix elements These can arise naturally due to time-varying parameters that appear in 1-x terms in rate formulas. The best way to avoid this is to use the abs type of time-variation, so that logit transformations can be used directly on the changing parameters. This approach ensures that the parameter never leaves the interval between zero and one. It is also possible to update changing parameters on the logit scale, which would also solve this problem. See the Model of Piece-Wise Time-Variation for more details. To illustrate this use of the logit-scale time-variation model, we use a modified SIR model in which a certain proportion of infected individuals die at the end of the infection period. This proportion is increased at April 1 by three-times the previous value. sir_with_death = ( flexmodel( params = c( tau = 16, # infected period beta = 0.15, # transmssion rate p = 0.2 # proportion who die at the end of the infected period ), state = c(S = 20000, I = 100, R = 0, D = 0), start_date = &quot;2000-01-01&quot;, end_date = &quot;2000-05-01&quot;, do_hazard = TRUE ) %&gt;% add_state_param_sum(&quot;N&quot;, &quot;^(S|I|R)$&quot;) %&gt;% add_rate(&quot;S&quot;, &quot;I&quot;, ~ (1/N) * (beta) * (I)) %&gt;% add_rate(&quot;I&quot;, &quot;R&quot;, ~ (1/tau) * (1-p)) %&gt;% add_rate(&quot;I&quot;, &quot;D&quot;, ~ (1/tau) * (p)) ) plot_with_death_rates = function(value, type) { (sir_with_death %&gt;% update_piece_wise( data.frame( Date = &quot;2000-04-01&quot;, Symbol = &quot;p&quot;, Value = value, Type = type )) %&gt;% simulation_history %&gt;% pivot_longer(-Date, names_to = &quot;rate&quot;) %&gt;% filter(grepl(&quot;_to_&quot;, rate)) %&gt;% ggplot + geom_line(aes(Date, value, colour = rate)) ) } plot_with_death_rates(3, &#39;rel_prev&#39;) In this example the rate at which infected individuals die becomes higher on April 1. This increase necessarily corresponds to a drop in the rate at which infected individuals live, but the drop does not push the rate below zero in this case. But importantly there are no structural restrictions that keep the rates positive when the 'rel_prev' method is used. We can illustrate this by increasing the multiplier from three to six. plot_with_death_rates(6, &#39;rel_prev&#39;) Note that we have suppressed warnings about negative rates, which are clearly visible on the plot above. These negative rates can be completely avoided by specifying the increase on the logit scale with the 'rel_prev_logit' type. plot_with_death_rates(6, &#39;rel_prev_logit&#39;) This means that the log-odds of death after infection additively increases by six on April 1. The log odds could be made as high as one wants, and the rate at which infected individuals live would never drop below zero. 16.1.3 Optimizer tries very large dispersion parameters For some reason the TMB dnbinom2 function cannot handle large dispersion parameters, even though the standard R dnbinom function seems fine with them. Nevertheless, this entire issue can be avoided by setting priors on the dispersion parameters. In the future we might try to exploit the fact that the limit of the log negative binomial density as the dispersion parameter gets large tends to the log poisson density. Such an improvement is not entirely trivial due to the need for maintaining differentiability. 16.2 Non-Positive Definite Covariance Matrix When generating ensemble forecasts … Use PDify = TRUE … "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
